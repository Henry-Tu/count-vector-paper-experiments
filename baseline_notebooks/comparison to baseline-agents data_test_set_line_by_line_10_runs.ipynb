{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_docker.pkl  data_prod.pkl  data_prod_test.pkl\r\n"
     ]
    }
   ],
   "source": [
    "%ls /var/data/paper_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 500)\n",
    "# import sys\n",
    "# sys.path.append('michael/deeplearn.det/deeplearn')  \n",
    "# from model import evaluation_print\n",
    "# from michael//deeplearn.det//deeplearn//model import evaluation_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a, b, c=np.ones((2,8)), np.ones((2,8)), np.ones((2,8))\n",
    "np.vstack([a,b,c]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_preproc(a):\n",
    "    \"\"\"\n",
    "       input string\n",
    "       output string without not relevant stuff\n",
    "       example: input \"mailservice_nimol_server_qmgr.nimol.hist\"\n",
    "                output \"mailservice\\_server\\_qmgr\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    spl = a.split('_')\n",
    "    return '\\_'.join([spl[0], spl[2], spl[3].split('.')[0]])\n",
    "\n",
    "def top_n_predicted(probs, true_labels, top_n_value):\n",
    "    \"\"\"\n",
    "    input: probabilites per 'point', and true_labels, and top_n value\n",
    "    output: labels for predictions. If the true probabilit are within top_n values\n",
    "    it returns the true label in its output, otherwise it returns the argmax.\n",
    "    \"\"\"\n",
    "    predicted_labels_top = []\n",
    "\n",
    "    for line, true_label in zip(probs, true_labels):\n",
    "        sorted_probs = np.argsort(line)[::-1][:top_n_value]\n",
    "        if true_label in sorted_probs:\n",
    "            predicted_labels_top.append(true_label)\n",
    "        else:\n",
    "            predicted_labels_top.append(sorted_probs[0])\n",
    "\n",
    "\n",
    "    return predicted_labels_top\n",
    "\n",
    "def top_n(vals, names, top_n_val):\n",
    "    top_sorted_indexes = np.argsort(vals)[::-1][:top_n_val]\n",
    "    return [names[i] for i in top_sorted_indexes]\n",
    "\n",
    "def evaluation_print(true_labels, prediction, process_names, top_n_value=1):\n",
    "\n",
    "#     if top_n > 1:\n",
    "#         # print prediction\n",
    "#         predicted_labels = top_n_predicted(prediction, true_labels, top_n_value=top_n_value)\n",
    "#         # predicted_labels\n",
    "#     elif top_n_value == 1:\n",
    "#         predicted_labels = prediction\n",
    "    predicted_labels = prediction\n",
    "    np.set_printoptions(precision=6, suppress=True)\n",
    "    np.set_printoptions(threshold=10000, linewidth=1000)\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "#     process_names = [string_preproc(nam) for nam in process_names]\n",
    "    print process_names\n",
    "    print 'top_n = ', top_n_value\n",
    "    # print conf_matrix\n",
    "\n",
    "    n = conf_matrix.shape[0]\n",
    "    print pd.DataFrame(conf_matrix, index=range(n), columns=range(n))\n",
    "\n",
    "    print 'macro average recall', '%.2f' % recall_score(true_labels, predicted_labels, average='macro')\n",
    "    print 'macro average precision', '%.2f' % precision_score(true_labels, predicted_labels, average='macro')\n",
    "    print '\\\\begin{tabular} {rrr}'\n",
    "    print '\\\\hline'\n",
    "    for i, (name, recall, precision) in enumerate(zip(\n",
    "                            process_names,\n",
    "                            recall_score(true_labels, predicted_labels, average=None),\n",
    "                            precision_score(true_labels, predicted_labels, average=None)\n",
    "                                      )):\n",
    "        print i, name, '&', '%.4f' % recall, '&', '%.4f' % precision, '\\\\\\\\'\n",
    "        # print name, '%.4f' % recall, '%.4f' % precision\n",
    "\n",
    "    print '\\\\hline'\n",
    "    print '\\\\end{tabular}'\n",
    "\n",
    "    print '\\n' * 2\n",
    "#     conf_matrix = np.hstack([np.array(range(n), ndmin=2).T, conf_matrix])\n",
    "#     conf_matrix = np.vstack([[0] + range(n), conf_matrix])\n",
    "#     print(tabulate(conf_matrix, tablefmt=\"latex\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.8 s, sys: 2.24 s, total: 38 s\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%time data_train, proc_names = joblib.load('/var/data/paper_data/data_prod.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_blocks_train = [d for _, d in data_train]\n",
    "labels_train = [np.argmax(l) for l, _ in data_train]\n",
    "labels_train = [[l] * 10 for l in labels_train]\n",
    "labels_train = [item for sublist in labels_train for item in sublist]\n",
    "data_sum_train = [d.sum(axis=0) for d in data_blocks_train]\n",
    "data_concat_train = [d.ravel() for d in data_blocks_train]\n",
    "data_lines_train = np.vstack(data_blocks_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.4 s, sys: 3.2 s, total: 56.6 s\n",
      "Wall time: 56.6 s\n"
     ]
    }
   ],
   "source": [
    "%time data_test, proc_names = joblib.load('/var/data/paper_data/data_prod_test.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_blocks_test = [d for _, d in data_test]\n",
    "labels_test = [np.argmax(l) for l, _ in data_test]\n",
    "labels_test = [[l] * 10 for l in labels_test]\n",
    "labels_test = [item for sublist in labels_test for item in sublist]\n",
    "\n",
    "data_sum_test = [d.sum(axis=0) for d in data_blocks_test]\n",
    "data_concat_test = [d.ravel() for d in data_blocks_test]\n",
    "data_lines_test = np.vstack(data_blocks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(n_jobs=12, verbose=5)\n",
    "# clf = LinearSVC(C=1)\n",
    "# clf = RandomForestClassifier(n_jobs=12)\n",
    "# clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=12,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=5, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(data_lines_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5719700, 324)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lines_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = clf.predict(data_lines_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 2 * 10 **6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro average recall 0.74\n",
      "macro average precision 0.79\n",
      "0 iscsid 1.0000 0.6689\n",
      "1 httpd 0.0000 0.0000\n",
      "2 cyagateway 1.0000 0.9992\n",
      "3 hsflowd 0.3476 0.9845\n",
      "4 ntpd 0.9999 0.6042\n",
      "5 bender 0.0075 0.9970\n",
      "6 cyacollector 0.9908 0.9999\n",
      "7 caldaemon 1.0000 1.0000\n",
      "8 appdisp 0.0000 0.0000\n",
      "9 syslog-ng 0.9994 0.9995\n",
      "10 java 1.0000 0.9999\n",
      "11 wrapper 1.0000 1.0000\n",
      "12 cma 0.0000 0.0000\n",
      "13 perfstat 0.9997 0.9998\n",
      "14 add_time.pl 0.9954 1.0000\n",
      "15 init 0.9998 1.0000\n",
      "16 tail 0.9998 1.0000\n",
      "17 svscan 0.9982 0.9925\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=6, suppress=True)\n",
    "np.set_printoptions(threshold=10000, linewidth=10000, edgeitems=10000)\n",
    "# print confusion_matrix(prediction, labels_test)\n",
    "print 'macro average recall', '%.2f' % recall_score(labels_test, prediction, average='macro')\n",
    "print 'macro average precision', '%.2f' % precision_score(labels_test, prediction, average='macro')\n",
    "for i, (name, recall, precision) in enumerate(zip(\n",
    "                            proc_names,\n",
    "                            recall_score(labels_test, prediction, average=None),\n",
    "                            precision_score(labels_test, prediction, average=None)\n",
    "                                      )):\n",
    "        print i, name, '%.4f' % recall, '%.4f' % precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iscsid', 'httpd', 'cyagateway', 'hsflowd', 'ntpd', 'bender', 'cyacollector', 'caldaemon', 'appdisp', 'syslog-ng', 'java', 'wrapper', 'cma', 'perfstat', 'add_time.pl', 'init', 'tail', 'svscan', 'yamproxy', 'nscd']\n",
      "top_n =  1\n",
      "        0   1       2       3       4     5       6       7   8       9       10      11  12      13      14     15     16     17\n",
      "0   991335   0       0       0       0     7       6       0   0       0       0       0   2       0       0      0      0      0\n",
      "1        0   0       0       0       0     0       0       0   0       0       0       0   0       0       0      0      0      0\n",
      "2        0   0  496897       0       0     0       0       0   0       0       9       0   0       0       0      0      0      4\n",
      "3        0   0       0  172740  324150     0       0       0   0       0       0       0   0       0       0      0      0      0\n",
      "4        0   0       0      64  494796     0       0       0   0       0       0       0   0       0       0      0      0      0\n",
      "5   490689   0       0       0       0  3684       2       0   0       0       0       0   5       0       0      0      0      0\n",
      "6        0   0     219    2123       0     0  281681       0   0       0       0       0   0       0       0      0      1    276\n",
      "7        0   8       0       0       0     0       0  494758   0       0       0       0   0       0       0      0      0      4\n",
      "8        0   0       0       0       0     0       0       0   0       0       0       0   0       0       0      0      0      0\n",
      "9        0  44     172       0       0     0       0       0   0  494794      25       0   0      25       3      0      0     17\n",
      "10       0   0       0       0       0     0       0       0   0       0  452878       0   0       2       0      0      0      0\n",
      "11       0   0       0       0       0     0       3       0   0       0       0  452857   0       0       0      0      0      0\n",
      "12       0   0       0       0       0     0       0       0   0       0       0       0   0       0       0      0      0      0\n",
      "13       0   9       0      10       0     0       0       0  24       0       0       0   0  164637       0      0      0      0\n",
      "14       0   0       0     515       0     1       0       0   0     229       0       0   0       1  160454      0      0      0\n",
      "15       0   0       0       0       8     0       0       0   0      10       0       0   0       0       2  99750      0      0\n",
      "16       0   7       0       0       0     3       6       0   0       0       0       3   0       0       0      0  99651      0\n",
      "17       0  64       1       6       0     0       0       0   0       0       0       0   0       1       0      0      0  40028\n",
      "macro average recall 0.74\n",
      "macro average precision 0.79\n",
      "\\begin{tabular} {rrr}\n",
      "\\hline\n",
      "0 iscsid & 1.0000 & 0.6689 \\\\\n",
      "1 httpd & 0.0000 & 0.0000 \\\\\n",
      "2 cyagateway & 1.0000 & 0.9992 \\\\\n",
      "3 hsflowd & 0.3476 & 0.9845 \\\\\n",
      "4 ntpd & 0.9999 & 0.6042 \\\\\n",
      "5 bender & 0.0075 & 0.9970 \\\\\n",
      "6 cyacollector & 0.9908 & 0.9999 \\\\\n",
      "7 caldaemon & 1.0000 & 1.0000 \\\\\n",
      "8 appdisp & 0.0000 & 0.0000 \\\\\n",
      "9 syslog-ng & 0.9994 & 0.9995 \\\\\n",
      "10 java & 1.0000 & 0.9999 \\\\\n",
      "11 wrapper & 1.0000 & 1.0000 \\\\\n",
      "12 cma & 0.0000 & 0.0000 \\\\\n",
      "13 perfstat & 0.9997 & 0.9998 \\\\\n",
      "14 add_time.pl & 0.9954 & 1.0000 \\\\\n",
      "15 init & 0.9998 & 1.0000 \\\\\n",
      "16 tail & 0.9998 & 1.0000 \\\\\n",
      "17 svscan & 0.9982 & 0.9925 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_print(true_labels=labels_test, prediction=prediction, process_names=proc_names,top_n_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n",
      " building tree 3 of 10\n",
      "building tree 2 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      " building tree 8 of 10building tree 7 of 10\n",
      " building tree 10 of 10\n",
      "building tree 9 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   7 out of  10 | elapsed:   29.4s remaining:   12.6s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:   34.2s finished\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    2.2s remaining:    5.2s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   7 out of  10 | elapsed:   28.8s remaining:   12.3s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:   33.3s finished\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    2.3s remaining:    5.3s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   7 out of  10 | elapsed:   32.4s remaining:   13.9s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:   34.9s finished\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    2.1s remaining:    5.0s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   7 out of  10 | elapsed:   30.7s remaining:   13.1s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:   34.7s finished\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    2.2s remaining:    5.1s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "building tree 1 of 10building tree 2 of 10\n",
      "\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   7 out of  10 | elapsed:   36.5s remaining:   15.6s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:   38.3s finished\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    2.3s remaining:    5.4s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      " building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   7 out of  10 | elapsed:   33.6s remaining:   14.4s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:   35.2s finished\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    2.1s remaining:    4.8s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10 building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   7 out of  10 | elapsed:   33.0s remaining:   14.1s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:   34.8s finished\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    2.4s remaining:    5.6s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10 \n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   7 out of  10 | elapsed:   33.6s remaining:   14.4s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:   35.7s finished\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    2.2s remaining:    5.2s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "building tree 1 of 10building tree 2 of 10\n",
      "\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   7 out of  10 | elapsed:   32.5s remaining:   13.9s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:   37.3s finished\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    2.3s remaining:    5.3s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   7 out of  10 | elapsed:   31.8s remaining:   13.6s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:   34.1s finished\n",
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    2.4s remaining:    5.6s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "r, p = [], []\n",
    "for i in range(10):\n",
    "#     clf = LogisticRegression(n_jobs=20, verbose=2)\n",
    "#     clf = LinearSVC(C=1, verbose=2)\n",
    "    clf = RandomForestClassifier(n_jobs=20, verbose=2)\n",
    "\n",
    "    clf.fit(data_lines_train, labels_train)\n",
    "    prediction = clf.predict(data_lines_test)\n",
    "    # print confusion_matrix(prediction, test_label)\n",
    "    r.append(recall_score(labels_test, prediction, average='macro'))\n",
    "    p.append(precision_score(labels_test, prediction, average='macro'))\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.850 0.0209846673912 0.795 0.0196401496198\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=3)\n",
    "print '%.3f' % np.mean(p), np.std(p), '%.3f' % np.mean(r), np.std(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LR\n",
    "0.791 0.0 0.741 1.11022302463e-16\n",
    "\n",
    "### Lin SVM\n",
    "\n",
    "0.792 1.11022302463e-16 0.741 0.0\n",
    "\n",
    "### RF\n",
    "\n",
    "0.850 0.0209846673912 0.795 0.0196401496198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
