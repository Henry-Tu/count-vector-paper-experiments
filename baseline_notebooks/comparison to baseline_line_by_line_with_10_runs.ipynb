{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix\n",
    "from tabulate import tabulate\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 500)\n",
    "# import sys\n",
    "# sys.path.append('michael/deeplearn.det/deeplearn')  \n",
    "# from model import evaluation_print\n",
    "# from michael//deeplearn.det//deeplearn//model import evaluation_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_preproc(a):\n",
    "    \"\"\"\n",
    "       input string\n",
    "       output string without not relevant stuff\n",
    "       example: input \"mailservice_nimol_server_qmgr.nimol.hist\"\n",
    "                output \"mailservice\\_server\\_qmgr\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    spl = a.split('_')\n",
    "    return '\\_'.join([spl[0], spl[2], spl[3].split('.')[0]])\n",
    "\n",
    "def top_n_predicted(probs, true_labels, top_n_value):\n",
    "    \"\"\"\n",
    "    input: probabilites per 'point', and true_labels, and top_n value\n",
    "    output: labels for predictions. If the true probabilit are within top_n values\n",
    "    it returns the true label in its output, otherwise it returns the argmax.\n",
    "    \"\"\"\n",
    "    predicted_labels_top = []\n",
    "\n",
    "    for line, true_label in zip(probs, true_labels):\n",
    "        sorted_probs = np.argsort(line)[::-1][:top_n_value]\n",
    "        if true_label in sorted_probs:\n",
    "            predicted_labels_top.append(true_label)\n",
    "        else:\n",
    "            predicted_labels_top.append(sorted_probs[0])\n",
    "\n",
    "\n",
    "    return predicted_labels_top\n",
    "\n",
    "def top_n(vals, names, top_n_val):\n",
    "    top_sorted_indexes = np.argsort(vals)[::-1][:top_n_val]\n",
    "    return [names[i] for i in top_sorted_indexes]\n",
    "\n",
    "def evaluation_print(true_labels, prediction, process_names, top_n_value=1):\n",
    "\n",
    "#     if top_n > 1:\n",
    "#         # print prediction\n",
    "#         predicted_labels = top_n_predicted(prediction, true_labels, top_n_value=top_n_value)\n",
    "#         # predicted_labels\n",
    "#     elif top_n_value == 1:\n",
    "#         predicted_labels = prediction\n",
    "    predicted_labels = prediction\n",
    "    np.set_printoptions(precision=6, suppress=True)\n",
    "    np.set_printoptions(threshold=10000, linewidth=1000)\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    process_names = [string_preproc(nam) for nam in process_names]\n",
    "    print process_names\n",
    "    print 'top_n = ', top_n_value\n",
    "    # print conf_matrix\n",
    "\n",
    "    n = conf_matrix.shape[0]\n",
    "    print pd.DataFrame(conf_matrix, index=range(n), columns=range(n))\n",
    "\n",
    "    print 'macro average recall', '%.2f' % recall_score(true_labels, predicted_labels, average='macro')\n",
    "    print 'macro average precision', '%.2f' % precision_score(true_labels, predicted_labels, average='macro')\n",
    "    print '\\\\begin{tabular} {rrr}'\n",
    "    print '\\\\hline'\n",
    "    for i, (name, recall, precision) in enumerate(zip(\n",
    "                            process_names,\n",
    "                            recall_score(true_labels, predicted_labels, average=None),\n",
    "                            precision_score(true_labels, predicted_labels, average=None)\n",
    "                                      )):\n",
    "        print i, name, '&', '%.4f' % recall, '&', '%.4f' % precision, '\\\\\\\\'\n",
    "        # print name, '%.4f' % recall, '%.4f' % precision\n",
    "\n",
    "    print '\\\\hline'\n",
    "    print '\\\\end{tabular}'\n",
    "\n",
    "    print '\\n' * 2\n",
    "    conf_matrix = np.hstack([np.array(range(n), ndmin=2).T, conf_matrix])\n",
    "    conf_matrix = np.vstack([[0] + range(n), conf_matrix])\n",
    "    print(tabulate(conf_matrix, tablefmt=\"latex\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_docker.pkl     data_prod.pkl       data_prod_test.pkl\r\n"
     ]
    }
   ],
   "source": [
    "%ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.22 s, sys: 405 ms, total: 3.62 s\n",
      "Wall time: 3.62 s\n"
     ]
    }
   ],
   "source": [
    "%time data, proc_names = joblib.load('data/data_docker.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_blocks = [d.T for _, d in data]\n",
    "labels = [np.argmax(l) for l, _ in data]\n",
    "labels = [[l] * 10 for l in labels]\n",
    "labels = [item for sublist in labels for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sum = [d.sum(axis=1) for d in data_blocks]\n",
    "data_concat = [d.ravel() for d in data_blocks]\n",
    "data_lines = np.vstack(data_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364500, 310)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_data, test_data, train_label, test_label = train_test_split(data_sum, labels, test_size=.2, random_state=100)\n",
    "train_data, test_data, train_label, test_label = train_test_split(data_lines, labels, test_size=.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72900"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "r, p = [], []\n",
    "for i in range(10):\n",
    "#     clf = LogisticRegression(n_jobs=8)\n",
    "    clf = LinearSVC(C=1)\n",
    "#     clf = RandomForestClassifier()\n",
    "\n",
    "    clf.fit(train_data, train_label)\n",
    "    prediction = clf.predict(test_data)\n",
    "    # print confusion_matrix(prediction, test_label)\n",
    "    r.append(recall_score(test_label, prediction, average='macro'))\n",
    "    p.append(precision_score(test_label, prediction, average='macro'))\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.850 1.11022302463e-16 0.827 1.11022302463e-16\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=3)\n",
    "print '%.3f' % np.mean(p), np.std(p), '%.3f' % np.mean(r), np.std(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
